function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError("Cannot call a class as a function"); } }

function _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError("this hasn't been initialised - super() hasn't been called"); } return call && (typeof call === "object" || typeof call === "function") ? call : self; }

function _inherits(subClass, superClass) { if (typeof superClass !== "function" && superClass !== null) { throw new TypeError("Super expression must either be null or a function, not " + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }

// cool blog article on how to do this: http://www.smartjava.org/content/exploring-html5-web-audio-visualizing-sound
// https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API

// distortion curve for the waveshaper, thanks to Kevin Ennis
// http://stackoverflow.com/questions/22312841/waveshaper-node-in-webaudio-how-to-emulate-distortion

import React, { Component } from 'react';
import { MicrophoneRecorder } from '../libs/MicrophoneRecorder';
import AudioContext from '../libs/AudioContext';

var WIDTH = "640";
var HEIGHT = "100";

var ReactMic = function (_Component) {
  _inherits(ReactMic, _Component);

  function ReactMic(props) {
    _classCallCheck(this, ReactMic);

    var _this = _possibleConstructorReturn(this, _Component.call(this, props));

    _this.visualize = function (analyser, visualizerCanvas, visualizerCanvasCtx) {
      var self = _this;
      var _this$props = _this.props,
          backgroundColor = _this$props.backgroundColor,
          strokeColor = _this$props.strokeColor;


      var bufferLength = analyser.fftSize;

      var dataArray = new Uint8Array(bufferLength);

      visualizerCanvasCtx.clearRect(0, 0, WIDTH, HEIGHT);

      function draw() {

        var drawVisual = requestAnimationFrame(draw);

        analyser.getByteTimeDomainData(dataArray);

        visualizerCanvasCtx.fillStyle = backgroundColor;
        visualizerCanvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

        visualizerCanvasCtx.lineWidth = 3;
        visualizerCanvasCtx.strokeStyle = strokeColor;

        visualizerCanvasCtx.beginPath();

        var sliceWidth = WIDTH * 1.0 / bufferLength;
        var x = 0;

        for (var i = 0; i < bufferLength; i++) {
          var v = dataArray[i] / 128.0;
          var y = v * HEIGHT / 2;

          if (i === 0) {
            visualizerCanvasCtx.moveTo(x, y);
          } else {
            visualizerCanvasCtx.lineTo(x, y);
          }

          x += sliceWidth;
        }

        visualizerCanvasCtx.lineTo(visualizerCanvas.width, visualizerCanvas.height / 2);
        visualizerCanvasCtx.stroke();
      };

      draw();
    };

    _this.state = {
      audioCtx: null,
      analyser: null,
      microphoneRecorder: null,
      visualizerCanvas: null,
      visualizerCanvasCtx: null
    };
    return _this;
  }

  ReactMic.prototype.componentDidMount = function componentDidMount() {
    var self = this;
    var onStop = this.props.onStop;

    var analyser = AudioContext.getAnalyser();
    var visualizerCanvas = this.refs.visualizer;
    var visualizerCanvasCtx = this.refs.visualizer.getContext("2d");

    analyser.minDecibels = -90;
    analyser.maxDecibels = -10;
    analyser.smoothingTimeConstant = 0.85;
    analyser.fftSize = 2048;

    this.setState({
      analyser: analyser,
      microphoneRecorder: new MicrophoneRecorder(onStop),
      visualizerCanvas: visualizerCanvas,
      visualizerCanvasCtx: visualizerCanvasCtx
    });

    this.visualize(analyser, visualizerCanvas, visualizerCanvasCtx);
  };

  ReactMic.prototype.render = function render() {
    var _props = this.props,
        record = _props.record,
        onStop = _props.onStop;
    var _state = this.state,
        analyser = _state.analyser,
        audioCtx = _state.audioCtx,
        microphoneRecorder = _state.microphoneRecorder;


    if (record) {
      if (microphoneRecorder) {
        microphoneRecorder.startRecording();
      }
    } else {
      if (microphoneRecorder) {
        microphoneRecorder.stopRecording(onStop);
      }
    }

    return React.createElement('canvas', { ref: 'visualizer', className: this.props.className });
  };

  return ReactMic;
}(Component);

export { ReactMic as default };


process.env.NODE_ENV !== "production" ? ReactMic.propTypes = {
  backgroundColor: React.PropTypes.string,
  strokeColor: React.PropTypes.string,
  className: React.PropTypes.string,
  height: React.PropTypes.number,
  record: React.PropTypes.bool.isRequired,
  onStop: React.PropTypes.func
} : void 0;

ReactMic.defaultProps = {
  backgroundColor: '#4bb8d1',
  strokeColor: '#000000',
  className: 'visualizer',
  record: false
};