{"version":3,"sources":["webpack:///webpack/universalModuleDefinition","webpack:///react-mic.min.js","webpack:///webpack/bootstrap a3574d70cf957c192a7c","webpack:///./src/libs/AudioContext.js","webpack:///./src/components/ReactMic.js","webpack:///./src/libs/MicrophoneRecorder.js","webpack:///external {\"root\":\"React\",\"commonjs2\":\"react\",\"commonjs\":\"react\",\"amd\":\"react\"}"],"names":["root","factory","exports","module","require","define","amd","this","__WEBPACK_EXTERNAL_MODULE_4__","modules","__webpack_require__","moduleId","installedModules","i","l","call","m","c","value","d","name","getter","o","Object","defineProperty","configurable","enumerable","get","n","__esModule","object","property","prototype","hasOwnProperty","p","s","__webpack_exports__","audioCtx","window","AudioContext","webkitAudioContext","analyser","createAnalyser","getAudioContext","getAnalyser","__WEBPACK_IMPORTED_MODULE_0__components_ReactMic__","_classCallCheck","instance","Constructor","TypeError","_possibleConstructorReturn","self","ReferenceError","_inherits","subClass","superClass","create","constructor","writable","setPrototypeOf","__proto__","__WEBPACK_IMPORTED_MODULE_0_react__","__WEBPACK_IMPORTED_MODULE_0_react___default","__WEBPACK_IMPORTED_MODULE_1__libs_MicrophoneRecorder__","__WEBPACK_IMPORTED_MODULE_2__libs_AudioContext__","ReactMic","WIDTH","HEIGHT","_Component","props","_this","visualize","visualizerCanvas","visualizerCanvasCtx","draw","requestAnimationFrame","getByteTimeDomainData","dataArray","fillStyle","backgroundColor","fillRect","lineWidth","strokeStyle","strokeColor","beginPath","sliceWidth","bufferLength","x","v","y","moveTo","lineTo","width","height","stroke","_this$props","fftSize","Uint8Array","clearRect","state","microphoneRecorder","componentDidMount","onStop","refs","visualizer","getContext","minDecibels","maxDecibels","smoothingTimeConstant","setState","render","_props","record","_state","startRecording","stopRecording","a","createElement","ref","className","defaultProps","__WEBPACK_IMPORTED_MODULE_0__AudioContext__","MicrophoneRecorder","mediaRecorder","chunks","startTime","stream","onStopCallback","constraints","audio","video","navigator","getUserMedia","webkitGetUserMedia","mozGetUserMedia","msGetUserMedia","callback","Date","now","resume","start","createMediaStreamSource","connect","mediaDevices","console","log","then","str","MediaRecorder","onstop","ondataavailable","event","push","data","alert","stop","suspend","evt","blob","Blob","type","blobObject","stopTime","blobURL","URL","createObjectURL"],"mappings":";;;;CAAA,SAAAA,EAAAC,GACA,gBAAAC,UAAA,gBAAAC,QACAA,OAAAD,QAAAD,EAAAG,QAAA,UACA,kBAAAC,gBAAAC,IACAD,QAAA,SAAAJ,GACA,gBAAAC,SACAA,QAAA,aAAAD,EAAAG,QAAA,UAEAJ,EAAA,aAAAC,EAAAD,EAAA,QACCO,KAAA,SAAAC,GACD,MCAgB,UAAUC,GCN1B,QAAAC,GAAAC,GAGA,GAAAC,EAAAD,GACA,MAAAC,GAAAD,GAAAT,OAGA,IAAAC,GAAAS,EAAAD,IACAE,EAAAF,EACAG,GAAA,EACAZ,WAUA,OANAO,GAAAE,GAAAI,KAAAZ,EAAAD,QAAAC,IAAAD,QAAAQ,GAGAP,EAAAW,GAAA,EAGAX,EAAAD,QAvBA,GAAAU,KA+DA,OAnCAF,GAAAM,EAAAP,EAGAC,EAAAO,EAAAL,EAGAF,EAAAG,EAAA,SAAAK,GAA2C,MAAAA,IAG3CR,EAAAS,EAAA,SAAAjB,EAAAkB,EAAAC,GACAX,EAAAY,EAAApB,EAAAkB,IACAG,OAAAC,eAAAtB,EAAAkB,GACAK,cAAA,EACAC,YAAA,EACAC,IAAAN,KAMAX,EAAAkB,EAAA,SAAAzB,GACA,GAAAkB,GAAAlB,KAAA0B,WACA,WAA2B,MAAA1B,GAAA,SAC3B,WAAiC,MAAAA,GAEjC,OADAO,GAAAS,EAAAE,EAAA,IAAAA,GACAA,GAIAX,EAAAY,EAAA,SAAAQ,EAAAC,GAAsD,MAAAR,QAAAS,UAAAC,eAAAlB,KAAAe,EAAAC,IAGtDrB,EAAAwB,EAAA,GAGAxB,IAAAyB,EAAA,KDgBM,SAAUhC,EAAQiC,EAAqB1B,GAE7C,YElFA,IAAM2B,GAAW,IAAKC,OAAOC,cAAgBD,OAAOE,oBAC9CC,EAAWJ,EAASK,iBAEpBH,GAEJI,gBAFoB,WAGlB,MAAON,IAGTO,YANoB,WAOlB,MAAOH,IAKXL,GAAA,EAAeG,GFoFT,SAAUpC,EAAQiC,EAAqB1B,GAE7C,YACAa,QAAOC,eAAeY,EAAqB,cAAgBlB,OAAO,GAC7C,IAAI2B,GAAqDnC,EAAoB,EACjEA,GAAoBS,EAAEiB,EAAqB,WAAY,WAAa,MAAOS,GAAsD,KAO5J,SAAU1C,EAAQiC,EAAqB1B,GAE7C,YAMA,SAASoC,GAAgBC,EAAUC,GAAe,KAAMD,YAAoBC,IAAgB,KAAM,IAAIC,WAAU,qCAEhH,QAASC,GAA2BC,EAAMpC,GAAQ,IAAKoC,EAAQ,KAAM,IAAIC,gBAAe,4DAAgE,QAAOrC,GAAyB,gBAATA,IAAqC,kBAATA,GAA8BoC,EAAPpC,EAElO,QAASsC,GAAUC,EAAUC,GAAc,GAA0B,kBAAfA,IAA4C,OAAfA,EAAuB,KAAM,IAAIN,WAAU,iEAAoEM,GAAeD,GAAStB,UAAYT,OAAOiC,OAAOD,GAAcA,EAAWvB,WAAayB,aAAevC,MAAOoC,EAAU5B,YAAY,EAAOgC,UAAU,EAAMjC,cAAc,KAAe8B,IAAYhC,OAAOoC,eAAiBpC,OAAOoC,eAAeL,EAAUC,GAAcD,EAASM,UAAYL,GAT5c,GAAIM,GAAsCnD,EAAoB,GAC1DoD,EAA8CpD,EAAoBkB,EAAEiC,GACpEE,EAAyDrD,EAAoB,GAC7EsD,EAAmDtD,EAAoB,EACjEA,GAAoBS,EAAEiB,EAAqB,IAAK,WAAa,MAAO6B,IG5GnG,IAAMC,GAAM,MACNC,EAAQ,MAEOF,EH6HN,SAAUG,GG5HvB,QAAAH,GAAYI,GAAOvB,EAAAvC,KAAA0D,EAAA,IAAAK,GAAApB,EAAA3C,KACjB6D,EAAArD,KAAAR,KAAM8D,GADW,OAAAC,GAiCnBC,UAAW,SAAC9B,EAAU+B,EAAkBC,GAUtC,QAASC,KAEYC,sBAAsBD,EAEzCjC,GAASmC,sBAAsBC,GAE/BJ,EAAoBK,UAAYC,EAChCN,EAAoBO,SAAS,EAAG,EAAGd,EAAOC,GAE1CM,EAAoBQ,UAAY,EAChCR,EAAoBS,YAAcC,EAElCV,EAAoBW,WAKpB,KAAI,GAHAC,GAAqB,EAARnB,EAAcoB,EAC3BC,EAAI,EAEA1E,EAAI,EAAGA,EAAIyE,EAAczE,IAAK,CACpC,GAAI2E,GAAIX,EAAUhE,GAAK,IACnB4E,EAAID,EAAIrB,EAAO,CAEV,KAANtD,EACD4D,EAAoBiB,OAAOH,EAAGE,GAE9BhB,EAAoBkB,OAAOJ,EAAGE,GAGhCF,GAAKF,EAGPZ,EAAoBkB,OAAOnB,EAAiBoB,MAAOpB,EAAiBqB,OAAO,GAC3EpB,EAAoBqB,SAxCtB,GAD8DC,GAErBzB,EAAKD,MAAtCU,EAFsDgB,EAEtDhB,gBAAiBI,EAFqCY,EAErCZ,YAErBG,EAAe7C,EAASuD,QAExBnB,EAAY,GAAIoB,YAAWX,EAE/Bb,GAAoByB,UAAU,EAAG,EAAGhC,EAAOC,GAoC3CO,KA3EAJ,EAAK6B,OACH9D,SAAU,KACVI,SAAU,KACV2D,mBAAoB,KACpB5B,iBAAkB,KAClBC,oBAAqB,MAPNH,EH8OnB,MAjHAjB,GAAUY,EAAUG,GAmEpBH,EAASjC,UGrLTqE,kBHqLuC,WGpLrC,GACQC,GAAW/F,KAAK8D,MAAhBiC,OACF7D,EAAWuB,EAAA,EAAapB,cACxB4B,EAAmBjE,KAAKgG,KAAKC,WAC7B/B,EAAsBlE,KAAKgG,KAAKC,WAAWC,WAAW,KAE5DhE,GAASiE,aAAe,GACxBjE,EAASkE,aAAe,GACxBlE,EAASmE,sBAAwB,IACjCnE,EAASuD,QAAU,KAEnBzF,KAAKsG,UACHpE,SAAUA,EACV2D,mBAAoB,GAAIrC,GAAA,EAAmBuC,GAC3C9B,iBAAkBA,EAClBC,oBAAqBA,IAGvBlE,KAAKgE,UAAU9B,EAAU+B,EAAkBC,IHyL7CR,EAASjC,UGvIT8E,OHuI4B,WGvInB,GAAAC,GACoBxG,KAAK8D,MAAxB2C,EADDD,EACCC,OAAQV,EADTS,EACST,OADTW,EAE4C1G,KAAK4F,MAA5BC,GAFrBa,EAECxE,SAFDwE,EAEW5E,SAFX4E,EAEqBb,mBAY5B,OAVGY,GACEZ,GACDA,EAAmBc,iBAGjBd,GACFA,EAAmBe,cAAcb,GAKnCxC,EAAAsD,EAAAC,cAAA,UAAQC,IAAI,aAAaC,UAAWhH,KAAK8D,MAAMkD,aH+I5CtD,GG/O6BJ,EAAA,UA8GtCI,GAASuD,cACPzC,gBAAkB,UAClBI,YAAkB,UAClBoC,UAAkB,aAClBP,QAAkB,IH4Id,SAAU7G,EAAQiC,EAAqB1B,GAE7C,YAGA,SAASoC,GAAgBC,EAAUC,GAAe,KAAMD,YAAoBC,IAAgB,KAAM,IAAIC,WAAU,qCAF3F,GAAIwE,GAA8C/G,EAAoB,EAC5DA,GAAoBS,EAAEiB,EAAqB,IAAK,WAAa,MAAOsF,II7QnG,IAAIjF,UACAJ,SACAsF,SACAC,KACAC,SACAC,SAEAC,SAEEC,GAAgBC,OAAO,EAAMC,OAAO,EAE1CC,WAAUC,aAAgBD,UAAUC,cACVD,UAAUE,oBACVF,UAAUG,iBACVH,UAAUI,cAEpC,IAAab,GAAb,WACE,QAAAA,GAAYc,GAAU,GAAAlE,GAAA/D,IAAAuC,GAAAvC,KAAAmH,GAAAnH,KAqBtB2G,eAAe,WAab,GAVA7E,EAAWoF,EAAA,EAAa9E,kBACxBF,EAAWgF,EAAA,EAAa7E,cAGxBiF,EAAYY,KAAKC,MAEK,cAAnBrG,EAAS8D,OACV9D,EAASsG,SAGRhB,GAAyC,WAAxBA,EAAcxB,MAEhC,WADAwB,GAAcgB,QAIhB,IAAGhB,GAAyC,aAAxBA,EAAcxB,MAAsB,CACtDwB,EAAciB,MAAM,GACLvG,GAASwG,wBAAwBf,GACzCgB,QAAQrG,IAxBjB,OAfI0F,WAAUY,cACbC,QAAQC,IAAI,2BAEXd,UAAUY,aAAaX,aAAaJ,GAAakB,KAAK,SAACC,GACrDrB,EAASqB,EACTxB,EAAgB,GAAIyB,eAAcD,GAClCxB,EAAc0B,OAAS/E,EAAKgC,OAC5ByB,EAAiBS,EACjBb,EAAc2B,gBAAkB,SAACC,GAC/B3B,EAAO4B,KAAKD,EAAME,UAItBC,MAAM,wJAEDnJ,KAnBX,MAAAmH,GAAA1F,UA+CEmF,cA/CF,WAgDOQ,GAAyC,aAAxBA,EAAcxB,QAChCwB,EAAcgC,OACdtH,EAASuH,YAlDflC,EAAA1F,UAsDEsE,OAtDF,SAsDSuD,GACL,GAAMC,GAAO,GAAIC,MAAKnC,GAAUoC,KAAS,cACzCpC,KAEA,IAAMqC,IACJH,KAAYA,EACZjC,UAAYA,EACZqC,SAAYzB,KAAKC,MACjByB,QAAY7H,OAAO8H,IAAIC,gBAAgBP,GAGzC/B,GAAekC,IAjEnBvC,MJ2VM,SAAUvH,EAAQD,GK7WxBC,EAAAD,QAAAM,GLmXM,SAAUL,EAAQD,EAASQ,GAEjCP,EAAOD,QAAUQ,EAAoB","file":"react-mic.min.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory(require(\"react\"));\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([\"react\"], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"react-mic\"] = factory(require(\"react\"));\n\telse\n\t\troot[\"react-mic\"] = factory(root[\"React\"]);\n})(this, function(__WEBPACK_EXTERNAL_MODULE_4__) {\nreturn \n\n\n// WEBPACK FOOTER //\n// webpack/universalModuleDefinition","(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory(require(\"react\"));\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([\"react\"], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"react-mic\"] = factory(require(\"react\"));\n\telse\n\t\troot[\"react-mic\"] = factory(root[\"React\"]);\n})(this, function(__WEBPACK_EXTERNAL_MODULE_4__) {\nreturn /******/ (function(modules) { // webpackBootstrap\n/******/ \t// The module cache\n/******/ \tvar installedModules = {};\n/******/\n/******/ \t// The require function\n/******/ \tfunction __webpack_require__(moduleId) {\n/******/\n/******/ \t\t// Check if module is in cache\n/******/ \t\tif(installedModules[moduleId])\n/******/ \t\t\treturn installedModules[moduleId].exports;\n/******/\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = installedModules[moduleId] = {\n/******/ \t\t\ti: moduleId,\n/******/ \t\t\tl: false,\n/******/ \t\t\texports: {}\n/******/ \t\t};\n/******/\n/******/ \t\t// Execute the module function\n/******/ \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n/******/\n/******/ \t\t// Flag the module as loaded\n/******/ \t\tmodule.l = true;\n/******/\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/\n/******/\n/******/ \t// expose the modules object (__webpack_modules__)\n/******/ \t__webpack_require__.m = modules;\n/******/\n/******/ \t// expose the module cache\n/******/ \t__webpack_require__.c = installedModules;\n/******/\n/******/ \t// identity function for calling harmony imports with the correct context\n/******/ \t__webpack_require__.i = function(value) { return value; };\n/******/\n/******/ \t// define getter function for harmony exports\n/******/ \t__webpack_require__.d = function(exports, name, getter) {\n/******/ \t\tif(!__webpack_require__.o(exports, name)) {\n/******/ \t\t\tObject.defineProperty(exports, name, {\n/******/ \t\t\t\tconfigurable: false,\n/******/ \t\t\t\tenumerable: true,\n/******/ \t\t\t\tget: getter\n/******/ \t\t\t});\n/******/ \t\t}\n/******/ \t};\n/******/\n/******/ \t// getDefaultExport function for compatibility with non-harmony modules\n/******/ \t__webpack_require__.n = function(module) {\n/******/ \t\tvar getter = module && module.__esModule ?\n/******/ \t\t\tfunction getDefault() { return module['default']; } :\n/******/ \t\t\tfunction getModuleExports() { return module; };\n/******/ \t\t__webpack_require__.d(getter, 'a', getter);\n/******/ \t\treturn getter;\n/******/ \t};\n/******/\n/******/ \t// Object.prototype.hasOwnProperty.call\n/******/ \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n/******/\n/******/ \t// __webpack_public_path__\n/******/ \t__webpack_require__.p = \"\";\n/******/\n/******/ \t// Load entry module and return exports\n/******/ \treturn __webpack_require__(__webpack_require__.s = 5);\n/******/ })\n/************************************************************************/\n/******/ ([\n/* 0 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\nvar audioCtx = new (window.AudioContext || window.webkitAudioContext)();\nvar analyser = audioCtx.createAnalyser();\n\nvar AudioContext = {\n  getAudioContext: function getAudioContext() {\n    return audioCtx;\n  },\n  getAnalyser: function getAnalyser() {\n    return analyser;\n  }\n};\n\n/* harmony default export */ __webpack_exports__[\"a\"] = AudioContext;\n\n/***/ }),\n/* 1 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\nObject.defineProperty(__webpack_exports__, \"__esModule\", { value: true });\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0__components_ReactMic__ = __webpack_require__(2);\n/* harmony reexport (binding) */ __webpack_require__.d(__webpack_exports__, \"ReactMic\", function() { return __WEBPACK_IMPORTED_MODULE_0__components_ReactMic__[\"a\"]; });\n\n\n\n\n/***/ }),\n/* 2 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_react__ = __webpack_require__(4);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_react___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_0_react__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1__libs_MicrophoneRecorder__ = __webpack_require__(3);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_2__libs_AudioContext__ = __webpack_require__(0);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"a\", function() { return ReactMic; });\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n// cool blog article on how to do this: http://www.smartjava.org/content/exploring-html5-web-audio-visualizing-sound\n// https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API\n\n// distortion curve for the waveshaper, thanks to Kevin Ennis\n// http://stackoverflow.com/questions/22312841/waveshaper-node-in-webaudio-how-to-emulate-distortion\n\n\n\n\n\nvar WIDTH = \"640\";\nvar HEIGHT = \"100\";\n\nvar ReactMic = function (_Component) {\n  _inherits(ReactMic, _Component);\n\n  function ReactMic(props) {\n    _classCallCheck(this, ReactMic);\n\n    var _this = _possibleConstructorReturn(this, _Component.call(this, props));\n\n    _this.visualize = function (analyser, visualizerCanvas, visualizerCanvasCtx) {\n      var self = _this;\n      var _this$props = _this.props,\n          backgroundColor = _this$props.backgroundColor,\n          strokeColor = _this$props.strokeColor;\n\n\n      var bufferLength = analyser.fftSize;\n\n      var dataArray = new Uint8Array(bufferLength);\n\n      visualizerCanvasCtx.clearRect(0, 0, WIDTH, HEIGHT);\n\n      function draw() {\n\n        var drawVisual = requestAnimationFrame(draw);\n\n        analyser.getByteTimeDomainData(dataArray);\n\n        visualizerCanvasCtx.fillStyle = backgroundColor;\n        visualizerCanvasCtx.fillRect(0, 0, WIDTH, HEIGHT);\n\n        visualizerCanvasCtx.lineWidth = 3;\n        visualizerCanvasCtx.strokeStyle = strokeColor;\n\n        visualizerCanvasCtx.beginPath();\n\n        var sliceWidth = WIDTH * 1.0 / bufferLength;\n        var x = 0;\n\n        for (var i = 0; i < bufferLength; i++) {\n          var v = dataArray[i] / 128.0;\n          var y = v * HEIGHT / 2;\n\n          if (i === 0) {\n            visualizerCanvasCtx.moveTo(x, y);\n          } else {\n            visualizerCanvasCtx.lineTo(x, y);\n          }\n\n          x += sliceWidth;\n        }\n\n        visualizerCanvasCtx.lineTo(visualizerCanvas.width, visualizerCanvas.height / 2);\n        visualizerCanvasCtx.stroke();\n      };\n\n      draw();\n    };\n\n    _this.state = {\n      audioCtx: null,\n      analyser: null,\n      microphoneRecorder: null,\n      visualizerCanvas: null,\n      visualizerCanvasCtx: null\n    };\n    return _this;\n  }\n\n  ReactMic.prototype.componentDidMount = function componentDidMount() {\n    var self = this;\n    var onStop = this.props.onStop;\n\n    var analyser = __WEBPACK_IMPORTED_MODULE_2__libs_AudioContext__[\"a\" /* default */].getAnalyser();\n    var visualizerCanvas = this.refs.visualizer;\n    var visualizerCanvasCtx = this.refs.visualizer.getContext(\"2d\");\n\n    analyser.minDecibels = -90;\n    analyser.maxDecibels = -10;\n    analyser.smoothingTimeConstant = 0.85;\n    analyser.fftSize = 2048;\n\n    this.setState({\n      analyser: analyser,\n      microphoneRecorder: new __WEBPACK_IMPORTED_MODULE_1__libs_MicrophoneRecorder__[\"a\" /* MicrophoneRecorder */](onStop),\n      visualizerCanvas: visualizerCanvas,\n      visualizerCanvasCtx: visualizerCanvasCtx\n    });\n\n    this.visualize(analyser, visualizerCanvas, visualizerCanvasCtx);\n  };\n\n  ReactMic.prototype.render = function render() {\n    var _props = this.props,\n        record = _props.record,\n        onStop = _props.onStop;\n    var _state = this.state,\n        analyser = _state.analyser,\n        audioCtx = _state.audioCtx,\n        microphoneRecorder = _state.microphoneRecorder;\n\n\n    if (record) {\n      if (microphoneRecorder) {\n        microphoneRecorder.startRecording();\n      }\n    } else {\n      if (microphoneRecorder) {\n        microphoneRecorder.stopRecording(onStop);\n      }\n    }\n\n    return __WEBPACK_IMPORTED_MODULE_0_react___default.a.createElement('canvas', { ref: 'visualizer', className: this.props.className });\n  };\n\n  return ReactMic;\n}(__WEBPACK_IMPORTED_MODULE_0_react__[\"Component\"]);\n\n\n\n\nReactMic.defaultProps = {\n  backgroundColor: '#4bb8d1',\n  strokeColor: '#000000',\n  className: 'visualizer',\n  record: false\n};\n\n/***/ }),\n/* 3 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0__AudioContext__ = __webpack_require__(0);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"a\", function() { return MicrophoneRecorder; });\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n\n\nvar analyser = void 0;\nvar audioCtx = void 0;\nvar mediaRecorder = void 0;\nvar chunks = [];\nvar startTime = void 0;\nvar stream = void 0;\nvar blobObject = void 0;\nvar onStopCallback = void 0;\n\nvar constraints = { audio: true, video: false }; // constraints - only audio needed\n\nnavigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;\n\nvar MicrophoneRecorder = function () {\n  function MicrophoneRecorder(callback) {\n    var _this = this;\n\n    _classCallCheck(this, MicrophoneRecorder);\n\n    this.startRecording = function () {\n      var self = _this;\n\n      audioCtx = __WEBPACK_IMPORTED_MODULE_0__AudioContext__[\"a\" /* default */].getAudioContext();\n      analyser = __WEBPACK_IMPORTED_MODULE_0__AudioContext__[\"a\" /* default */].getAnalyser();\n\n      startTime = Date.now();\n\n      if (audioCtx.state === 'suspended') {\n        audioCtx.resume();\n      }\n\n      if (mediaRecorder && mediaRecorder.state === 'paused') {\n        mediaRecorder.resume();\n        return;\n      }\n\n      if (mediaRecorder && mediaRecorder.state === 'inactive') {\n        mediaRecorder.start(10);\n        var source = audioCtx.createMediaStreamSource(stream);\n        source.connect(analyser);\n      }\n    };\n\n    var self = this;\n\n    if (navigator.mediaDevices) {\n      console.log('getUserMedia supported.');\n\n      navigator.mediaDevices.getUserMedia(constraints).then(function (str) {\n        stream = str;\n        mediaRecorder = new MediaRecorder(str);\n        mediaRecorder.onstop = _this.onStop;\n        onStopCallback = callback;\n        mediaRecorder.ondataavailable = function (event) {\n          chunks.push(event.data);\n        };\n      });\n    } else {\n      alert('Unfortunately, your browser sucks.  Apple refuses to support the latest Web features in Safari.  Please tell them to upgrade the Safari Web browser.');\n    }\n    return this;\n  }\n\n  MicrophoneRecorder.prototype.stopRecording = function stopRecording() {\n    if (mediaRecorder && mediaRecorder.state !== 'inactive') {\n      mediaRecorder.stop();\n      audioCtx.suspend();\n    }\n  };\n\n  MicrophoneRecorder.prototype.onStop = function onStop(evt) {\n    var blob = new Blob(chunks, { 'type': 'audio/webm' });\n    chunks = [];\n\n    var blobObject = {\n      blob: blob,\n      startTime: startTime,\n      stopTime: Date.now(),\n      blobURL: window.URL.createObjectURL(blob)\n    };\n\n    onStopCallback(blobObject);\n  };\n\n  return MicrophoneRecorder;\n}();\n\n/***/ }),\n/* 4 */\n/***/ (function(module, exports) {\n\nmodule.exports = __WEBPACK_EXTERNAL_MODULE_4__;\n\n/***/ }),\n/* 5 */\n/***/ (function(module, exports, __webpack_require__) {\n\nmodule.exports = __webpack_require__(1);\n\n\n/***/ })\n/******/ ]);\n});\n\n\n// WEBPACK FOOTER //\n// react-mic.min.js"," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId])\n \t\t\treturn installedModules[moduleId].exports;\n\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// identity function for calling harmony imports with the correct context\n \t__webpack_require__.i = function(value) { return value; };\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 5);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap a3574d70cf957c192a7c","const audioCtx = new (window.AudioContext || window.webkitAudioContext)();\nconst analyser = audioCtx.createAnalyser();\n\nconst AudioContext  = {\n\n  getAudioContext() {\n    return audioCtx;\n  },\n\n  getAnalyser() {\n    return analyser;\n  }\n\n}\n\nexport default AudioContext;\n\n\n// WEBPACK FOOTER //\n// ./src/libs/AudioContext.js","// cool blog article on how to do this: http://www.smartjava.org/content/exploring-html5-web-audio-visualizing-sound\n// https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API\n\n// distortion curve for the waveshaper, thanks to Kevin Ennis\n// http://stackoverflow.com/questions/22312841/waveshaper-node-in-webaudio-how-to-emulate-distortion\n\nimport React, { Component } from 'react'\nimport { MicrophoneRecorder } from '../libs/MicrophoneRecorder';\nimport AudioContext from '../libs/AudioContext';\n\nconst WIDTH=\"640\";\nconst HEIGHT =\"100\";\n\nexport default class ReactMic extends Component {\n  constructor(props) {\n    super(props);\n    this.state = {\n      audioCtx: null,\n      analyser: null,\n      microphoneRecorder: null,\n      visualizerCanvas: null,\n      visualizerCanvasCtx: null\n    }\n  }\n\n  componentDidMount() {\n    const self = this;\n    const { onStop } = this.props;\n    const analyser = AudioContext.getAnalyser();\n    const visualizerCanvas = this.refs.visualizer;\n    const visualizerCanvasCtx = this.refs.visualizer.getContext(\"2d\");\n\n    analyser.minDecibels = -90;\n    analyser.maxDecibels = -10;\n    analyser.smoothingTimeConstant = 0.85;\n    analyser.fftSize = 2048;\n\n    this.setState({\n      analyser: analyser,\n      microphoneRecorder: new MicrophoneRecorder(onStop),\n      visualizerCanvas: visualizerCanvas,\n      visualizerCanvasCtx: visualizerCanvasCtx\n    });\n\n    this.visualize(analyser, visualizerCanvas, visualizerCanvasCtx);\n  }\n\n  visualize= (analyser, visualizerCanvas, visualizerCanvasCtx) => {\n    const self = this;\n    const { backgroundColor, strokeColor } = this.props;\n\n    var bufferLength = analyser.fftSize;\n\n    var dataArray = new Uint8Array(bufferLength);\n\n    visualizerCanvasCtx.clearRect(0, 0, WIDTH, HEIGHT);\n\n    function draw() {\n\n      const drawVisual = requestAnimationFrame(draw);\n\n      analyser.getByteTimeDomainData(dataArray);\n\n      visualizerCanvasCtx.fillStyle = backgroundColor;\n      visualizerCanvasCtx.fillRect(0, 0, WIDTH, HEIGHT);\n\n      visualizerCanvasCtx.lineWidth = 3;\n      visualizerCanvasCtx.strokeStyle = strokeColor;\n\n      visualizerCanvasCtx.beginPath();\n\n      var sliceWidth = WIDTH * 1.0 / bufferLength;\n      var x = 0;\n\n      for(var i = 0; i < bufferLength; i++) {\n        var v = dataArray[i] / 128.0;\n        var y = v * HEIGHT/2;\n\n        if(i === 0) {\n          visualizerCanvasCtx.moveTo(x, y);\n        } else {\n          visualizerCanvasCtx.lineTo(x, y);\n        }\n\n        x += sliceWidth;\n      }\n\n      visualizerCanvasCtx.lineTo(visualizerCanvas.width, visualizerCanvas.height/2);\n      visualizerCanvasCtx.stroke();\n    };\n\n    draw();\n  }\n\n  render() {\n    const { record, onStop } = this.props;\n    const { analyser, audioCtx, microphoneRecorder } = this.state;\n\n    if(record) {\n      if(microphoneRecorder) {\n        microphoneRecorder.startRecording();\n      }\n    } else {\n      if (microphoneRecorder) {\n        microphoneRecorder.stopRecording(onStop);\n      }\n    }\n\n    return (\n      <canvas ref=\"visualizer\" className={this.props.className}></canvas>\n    );\n  }\n}\n\nReactMic.propTypes = {\n  backgroundColor : React.PropTypes.string,\n  strokeColor     : React.PropTypes.string,\n  className       : React.PropTypes.string,\n  height          : React.PropTypes.number,\n  record          : React.PropTypes.bool.isRequired,\n  onStop          : React.PropTypes.func\n};\n\nReactMic.defaultProps = {\n  backgroundColor : '#4bb8d1',\n  strokeColor     : '#000000',\n  className       : 'visualizer',\n  record          : false\n}\n\n\n// WEBPACK FOOTER //\n// ./src/components/ReactMic.js","import AudioContext from './AudioContext';\n\nlet analyser;\nlet audioCtx;\nlet mediaRecorder;\nlet chunks = [];\nlet startTime;\nlet stream;\nlet blobObject;\nlet onStopCallback;\n\nconst constraints = { audio: true, video: false }; // constraints - only audio needed\n\nnavigator.getUserMedia = (navigator.getUserMedia ||\n                          navigator.webkitGetUserMedia ||\n                          navigator.mozGetUserMedia ||\n                          navigator.msGetUserMedia);\n\nexport class MicrophoneRecorder {\n  constructor(callback) {\n    const self = this;\n\n    if (navigator.mediaDevices) {\n     console.log('getUserMedia supported.');\n\n      navigator.mediaDevices.getUserMedia(constraints).then((str) => {\n        stream = str;\n        mediaRecorder = new MediaRecorder(str);\n        mediaRecorder.onstop = this.onStop;\n        onStopCallback = callback;\n        mediaRecorder.ondataavailable = (event) => {\n          chunks.push(event.data);\n        }\n      });\n    } else {\n      alert('Unfortunately, your browser sucks.  Apple refuses to support the latest Web features in Safari.  Please tell them to upgrade the Safari Web browser.')\n    }\n    return this;\n  }\n\n  startRecording=() => {\n    const self = this;\n\n    audioCtx = AudioContext.getAudioContext();\n    analyser = AudioContext.getAnalyser();\n\n\n    startTime = Date.now();\n\n    if(audioCtx.state === 'suspended') {\n      audioCtx.resume();\n    }\n\n    if(mediaRecorder && mediaRecorder.state === 'paused') {\n      mediaRecorder.resume();\n      return;\n    }\n\n    if(mediaRecorder && mediaRecorder.state === 'inactive') {\n      mediaRecorder.start(10);\n      const source = audioCtx.createMediaStreamSource(stream);\n      source.connect(analyser);\n    }\n  }\n\n  stopRecording() {\n    if(mediaRecorder && mediaRecorder.state !== 'inactive') {\n      mediaRecorder.stop();\n      audioCtx.suspend();\n    }\n  }\n\n  onStop(evt) {\n    const blob = new Blob(chunks, { 'type' : 'audio/webm' });\n    chunks = [];\n\n    const blobObject =  {\n      blob      : blob,\n      startTime : startTime,\n      stopTime  : Date.now(),\n      blobURL   : window.URL.createObjectURL(blob)\n    }\n\n    onStopCallback(blobObject);\n\n  }\n\n}\n\n\n// WEBPACK FOOTER //\n// ./src/libs/MicrophoneRecorder.js","module.exports = __WEBPACK_EXTERNAL_MODULE_4__;\n\n\n//////////////////\n// WEBPACK FOOTER\n// external {\"root\":\"React\",\"commonjs2\":\"react\",\"commonjs\":\"react\",\"amd\":\"react\"}\n// module id = 4\n// module chunks = 0"],"sourceRoot":""}